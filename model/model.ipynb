{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\garbage-classification\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/mostafaabla/garbage-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Windows-10-10.0.22621-SP0\n",
      "PyTorch Version: 2.1.1+cu121\n",
      "Python 3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]\n",
      "NVIDIA/CUDA GPU is available\n",
      "MPS (Apple Metal) is NOT AzVAILABLE\n",
      "Target device is cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import platform\n",
    "has_gpu = torch.cuda.is_available()\n",
    "# has_mps = getattr(torch,'has_mps',False)\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if torch.backends.mps.is_built() \\\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Python {sys.version}\")\n",
    "print(\"NVIDIA/CUDA GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AzVAILABLE\")\n",
    "print(f\"Target device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sfaub\\OneDrive\\Desktop\\CodeJam\\CodeJam13\\model\\garbage-classification\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "dataPath = pathlib.Path.cwd() / \"garbage-classification\"\n",
    "\n",
    "print(dataPath)\n",
    "\n",
    "isFile = lambda path : path.is_file()\n",
    "\n",
    "imagePaths = list(filter(isFile, list(dataPath.rglob(\"*\"))))\n",
    "\n",
    "np.random.shuffle(imagePaths)\n",
    "\n",
    "#pathSamples = np.random.choice(imagePaths, 8000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6564, 3, 224, 224])\n",
      "torch.Size([6564])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "transformer = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.uint8, scale=True),\n",
    "    v2.Resize(size=(224, 224), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "trainInputImages = []\n",
    "\n",
    "validateInputImages = []\n",
    "\n",
    "testInputImages = []\n",
    "\n",
    "trainLabelsList = []\n",
    "\n",
    "validateLabelsList = []\n",
    "\n",
    "testLabelsList = []\n",
    "\n",
    "rejected = []\n",
    "\n",
    "for index in range(len(imagePaths)):\n",
    "    pathStr = str(imagePaths[index])\n",
    "    labelNum = -1\n",
    "    if 'battery' in pathStr:\n",
    "        labelNum = 0\n",
    "    elif 'biological' in pathStr:\n",
    "        labelNum = 1\n",
    "    elif 'brown-glass' in pathStr:\n",
    "        labelNum = 2\n",
    "    elif 'cardboard' in pathStr:\n",
    "        labelNum = 3\n",
    "    elif 'clothes' in pathStr:\n",
    "        continue\n",
    "    elif 'green-glass' in pathStr:\n",
    "        labelNum = 4\n",
    "    elif 'metal' in pathStr:\n",
    "        labelNum = 5\n",
    "    elif 'paper' in pathStr:\n",
    "        labelNum = 6\n",
    "    elif 'plastic' in pathStr:\n",
    "        labelNum = 7\n",
    "    elif 'shoes' in pathStr:\n",
    "        continue\n",
    "    elif 'trash' in pathStr:\n",
    "        labelNum = 8\n",
    "    elif 'white-glass' in pathStr:\n",
    "        labelNum = 9\n",
    "    if labelNum == -1:\n",
    "        continue\n",
    "    img = Image.open(pathStr).convert('RGB')\n",
    "    tensor = transformer(img)\n",
    "    if tensor.shape[0] != 3:\n",
    "        rejected.append(pathStr)\n",
    "        continue\n",
    "    if index < int(0.8*len(imagePaths)):\n",
    "        trainLabelsList.append(labelNum)\n",
    "        trainInputImages.append(tensor)\n",
    "    elif index < int(0.8*len(imagePaths) + 0.1*len(imagePaths)):\n",
    "        validateLabelsList.append(labelNum)\n",
    "        validateInputImages.append(tensor)\n",
    "    else:\n",
    "        testLabelsList.append(labelNum)\n",
    "        testInputImages.append(tensor)    \n",
    "    \n",
    "\n",
    "\n",
    "trainDataset = torch.stack(trainInputImages)\n",
    "trainLabels = torch.ByteTensor(trainLabelsList)\n",
    "\n",
    "print(trainDataset.shape)\n",
    "print(trainLabels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.conv1 = nn.Conv2d(3, 20, kernel_size=(5, 5))\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=(5, 5))\n",
    "        self.fc1 = nn.Linear(50*53*53, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.logSoftMax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.logSoftMax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.05191609130844265\n",
      "Epoch 2, Loss: 0.03215497430688648\n",
      "Epoch 3, Loss: 0.029171770062844684\n",
      "Epoch 4, Loss: 0.02726331649213067\n",
      "Epoch 5, Loss: 0.025446601407256235\n",
      "Epoch 6, Loss: 0.02396255709789353\n",
      "Epoch 7, Loss: 0.022329329282027202\n",
      "Epoch 8, Loss: 0.021291703385307177\n",
      "Epoch 9, Loss: 0.020555789408198515\n",
      "Epoch 10, Loss: 0.01919362228647519\n",
      "Epoch 11, Loss: 0.01872756094703\n",
      "Epoch 12, Loss: 0.018267412426484785\n",
      "Epoch 13, Loss: 0.017275603822932455\n",
      "Epoch 14, Loss: 0.016580390565138194\n",
      "Epoch 15, Loss: 0.016049251541504404\n",
      "Epoch 16, Loss: 0.015384963904845141\n",
      "Epoch 17, Loss: 0.015381955350411512\n",
      "Epoch 18, Loss: 0.015017369429488359\n",
      "Epoch 19, Loss: 0.014313582156141817\n",
      "Epoch 20, Loss: 0.01390664457439432\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(20):  # Adjust the number of epochs as needed\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(trainDataset), batch_size):\n",
    "        inputs, curLabels = trainDataset[i:i+batch_size].to(device), trainLabels[i:i+batch_size].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, curLabels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainDataset)}\")\n",
    "    \n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 81.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(trainDataset), batch_size):\n",
    "        inputs, curLabels = trainDataset[index:index+batch_size].to(device), trainLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the train set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 60.09%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validateDataset = torch.stack(validateInputImages)\n",
    "validateLabels = torch.ByteTensor(validateLabelsList)\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(validateDataset), batch_size):\n",
    "        inputs, curLabels = validateDataset[index:index+batch_size].to(device), validateLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the validation set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 58.23%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testDataset = torch.stack(testInputImages)\n",
    "testLabels = torch.ByteTensor(testLabelsList)\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(testDataset), batch_size):\n",
    "        inputs, curLabels = testDataset[index:index+batch_size].to(device), testLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), pathlib.Path.cwd() / 'model_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.01378597620599957\n",
      "Epoch 10, Loss: 0.013325799281534663\n",
      "Epoch 11, Loss: 0.012286025025109414\n",
      "Epoch 12, Loss: 0.012413067253968253\n",
      "Epoch 13, Loss: 0.012340471788668763\n",
      "Epoch 14, Loss: 0.011664982419744778\n",
      "Epoch 15, Loss: 0.011559715999618381\n",
      "Epoch 16, Loss: 0.011676222721590348\n",
      "Epoch 17, Loss: 0.010882926851710774\n",
      "Epoch 18, Loss: 0.010927187409399486\n",
      "Epoch 19, Loss: 0.011246479421145737\n",
      "Epoch 20, Loss: 0.01052427662810053\n",
      "Epoch 21, Loss: 0.010446096487266127\n",
      "Epoch 22, Loss: 0.010098035332090168\n",
      "Epoch 23, Loss: 0.009763605747369642\n",
      "Epoch 24, Loss: 0.009874290210636995\n",
      "Epoch 25, Loss: 0.009520403645810088\n",
      "Epoch 26, Loss: 0.009647335950228443\n",
      "Epoch 27, Loss: 0.009136708098021605\n",
      "Epoch 28, Loss: 0.008986311004991433\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(20):  # Adjust the number of epochs as needed\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(trainDataset), batch_size):\n",
    "        inputs, curLabels = trainDataset[i:i+batch_size].to(device), trainLabels[i:i+batch_size].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, curLabels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+9}, Loss: {running_loss / len(trainDataset)}\")\n",
    "    \n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 92.43%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(trainDataset), batch_size):\n",
    "        inputs, curLabels = trainDataset[index:index+batch_size].to(device), trainLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the train set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 59.62%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validateDataset = torch.stack(validateInputImages)\n",
    "validateLabels = torch.ByteTensor(validateLabelsList)\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(validateDataset), batch_size):\n",
    "        inputs, curLabels = validateDataset[index:index+batch_size].to(device), validateLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the validation set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 58.48%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testDataset = torch.stack(testInputImages)\n",
    "testLabels = torch.ByteTensor(testLabelsList)\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(testDataset), batch_size):\n",
    "        inputs, curLabels = testDataset[index:index+batch_size].to(device), testLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), pathlib.Path.cwd() / 'model_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.008532180437803414\n",
      "Epoch 1, Loss: 0.008912262953431921\n",
      "Epoch 2, Loss: 0.008606898446841475\n",
      "Epoch 3, Loss: 0.008783273253587598\n",
      "Epoch 4, Loss: 0.008594577225114716\n",
      "Epoch 5, Loss: 0.008402563915301357\n",
      "Epoch 6, Loss: 0.008104547581281842\n",
      "Epoch 7, Loss: 0.008012445696892351\n",
      "Epoch 8, Loss: 0.00815344656352805\n",
      "Epoch 9, Loss: 0.008102227921786649\n",
      "Epoch 10, Loss: 0.00782561153264252\n",
      "Epoch 11, Loss: 0.0075299883037714755\n",
      "Epoch 12, Loss: 0.007939996544015183\n",
      "Epoch 13, Loss: 0.007501538636334272\n",
      "Epoch 14, Loss: 0.007803875864423825\n",
      "Epoch 15, Loss: 0.007396730894562241\n",
      "Epoch 16, Loss: 0.007533089865605182\n",
      "Epoch 17, Loss: 0.007256252957890485\n",
      "Epoch 18, Loss: 0.007451622095923828\n",
      "Epoch 19, Loss: 0.007202051927282779\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(20):  # Adjust the number of epochs as needed\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(trainDataset), batch_size):\n",
    "        inputs, curLabels = trainDataset[i:i+batch_size].to(device), trainLabels[i:i+batch_size].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, curLabels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {running_loss / len(trainDataset)}\")\n",
    "    \n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(imagePaths)\n",
    "\n",
    "trainInputImages = []\n",
    "\n",
    "validateInputImages = []\n",
    "\n",
    "testInputImages = []\n",
    "\n",
    "trainLabelsList = []\n",
    "\n",
    "validateLabelsList = []\n",
    "\n",
    "testLabelsList = []\n",
    "\n",
    "rejected = []\n",
    "\n",
    "for index in range(len(imagePaths)):\n",
    "    pathStr = str(imagePaths[index])\n",
    "    labelNum = -1\n",
    "    if 'battery' in pathStr:\n",
    "        labelNum = 0\n",
    "    elif 'biological' in pathStr:\n",
    "        labelNum = 1\n",
    "    elif 'brown-glass' in pathStr:\n",
    "        labelNum = 2\n",
    "    elif 'cardboard' in pathStr:\n",
    "        labelNum = 3\n",
    "    elif 'clothes' in pathStr:\n",
    "        continue\n",
    "    elif 'green-glass' in pathStr:\n",
    "        labelNum = 4\n",
    "    elif 'metal' in pathStr:\n",
    "        labelNum = 5\n",
    "    elif 'paper' in pathStr:\n",
    "        labelNum = 6\n",
    "    elif 'plastic' in pathStr:\n",
    "        labelNum = 7\n",
    "    elif 'shoes' in pathStr:\n",
    "        continue\n",
    "    elif 'trash' in pathStr:\n",
    "        labelNum = 8\n",
    "    elif 'white-glass' in pathStr:\n",
    "        labelNum = 9\n",
    "    if labelNum == -1:\n",
    "        continue\n",
    "    img = Image.open(pathStr).convert('RGB')\n",
    "    tensor = transformer(img)\n",
    "    if tensor.shape[0] != 3:\n",
    "        rejected.append(pathStr)\n",
    "        continue\n",
    "    if index < int(0.8*len(imagePaths)):\n",
    "        trainLabelsList.append(labelNum)\n",
    "        trainInputImages.append(tensor)\n",
    "    elif index < int(0.8*len(imagePaths) + 0.1*len(imagePaths)):\n",
    "        validateLabelsList.append(labelNum)\n",
    "        validateInputImages.append(tensor)\n",
    "    else:\n",
    "        testLabelsList.append(labelNum)\n",
    "        testInputImages.append(tensor)    \n",
    "    \n",
    "\n",
    "\n",
    "trainDataset = torch.stack(trainInputImages)\n",
    "trainLabels = torch.ByteTensor(trainLabelsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.012511615788406311\n",
      "Epoch 1, Loss: 0.011149287291919946\n",
      "Epoch 2, Loss: 0.009994607316619518\n",
      "Epoch 3, Loss: 0.009894531785461106\n",
      "Epoch 4, Loss: 0.008863523162079614\n",
      "Epoch 5, Loss: 0.008828155196962525\n",
      "Epoch 6, Loss: 0.008237722362144774\n",
      "Epoch 7, Loss: 0.007817404111989164\n",
      "Epoch 8, Loss: 0.007812083718672822\n",
      "Epoch 9, Loss: 0.007689199029563913\n",
      "Epoch 10, Loss: 0.007697748350595861\n",
      "Epoch 11, Loss: 0.00702165092167369\n",
      "Epoch 12, Loss: 0.00726652832782392\n",
      "Epoch 13, Loss: 0.006826700773237683\n",
      "Epoch 14, Loss: 0.006419704258805147\n",
      "Epoch 15, Loss: 0.006772400106437899\n",
      "Epoch 16, Loss: 0.006751126973531654\n",
      "Epoch 17, Loss: 0.006708882833075625\n",
      "Epoch 18, Loss: 0.0066142819803673494\n",
      "Epoch 19, Loss: 0.006691806311199826\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(20):  # Adjust the number of epochs as needed\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(trainDataset), batch_size):\n",
    "        inputs, curLabels = trainDataset[i:i+batch_size].to(device), trainLabels[i:i+batch_size].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, curLabels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {running_loss / len(trainDataset)}\")\n",
    "    \n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 96.54%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(trainDataset), batch_size):\n",
    "        inputs, curLabels = trainDataset[index:index+batch_size].to(device), trainLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the train set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 82.96%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validateDataset = torch.stack(validateInputImages)\n",
    "validateLabels = torch.ByteTensor(validateLabelsList)\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(validateDataset), batch_size):\n",
    "        inputs, curLabels = validateDataset[index:index+batch_size].to(device), validateLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the validation set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 87.72%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testDataset = torch.stack(testInputImages)\n",
    "testLabels = torch.ByteTensor(testLabelsList)\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(0, len(testDataset), batch_size):\n",
    "        inputs, curLabels = testDataset[index:index+batch_size].to(device), testLabels[index:index+batch_size].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), pathlib.Path.cwd() / 'model_3.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codejam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
