{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./garbage-classification\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/mostafaabla/garbage-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Linux-6.5.9-arch2-1-x86_64-with-glibc2.38\n",
      "PyTorch Version: 2.1.1+cu121\n",
      "Python 3.11.0 (main, Mar  1 2023, 18:26:19) [GCC 11.2.0]\n",
      "NVIDIA/CUDA GPU is available\n",
      "MPS (Apple Metal) is NOT AzVAILABLE\n",
      "Target device is cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import platform\n",
    "has_gpu = torch.cuda.is_available()\n",
    "# has_mps = getattr(torch,'has_mps',False)\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if torch.backends.mps.is_built() \\\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Python {sys.version}\")\n",
    "print(\"NVIDIA/CUDA GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AzVAILABLE\")\n",
    "print(f\"Target device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/coldstuff1/codejam/CodeJam13/model/garbage-classification\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "dataPath = pathlib.Path.cwd() / \"garbage-classification\"\n",
    "\n",
    "print(dataPath)\n",
    "\n",
    "isFile = lambda path : path.is_file()\n",
    "\n",
    "imagePaths = list(filter(isFile, list(dataPath.rglob(\"*\"))))\n",
    "\n",
    "pathSamples = np.random.choice(imagePaths, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 256, 256])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "transformer = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.uint8, scale=True),\n",
    "    v2.RandomResizedCrop(size=(256, 256), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "inputImages = []\n",
    "\n",
    "labelsList = []\n",
    "\n",
    "rejected = []\n",
    "\n",
    "for path in pathSamples:\n",
    "    pathStr = str(path)\n",
    "    labelNum = -1\n",
    "    if 'battery' in pathStr:\n",
    "        labelNum = 0\n",
    "    elif 'biological' in pathStr:\n",
    "        labelNum = 1\n",
    "    elif 'brown-glass' in pathStr:\n",
    "        labelNum = 2\n",
    "    elif 'cardboard' in pathStr:\n",
    "        labelNum = 3\n",
    "    elif 'clothes' in pathStr:\n",
    "        labelNum = 4\n",
    "    elif 'green-glass' in pathStr:\n",
    "        labelNum = 5\n",
    "    elif 'metal' in pathStr:\n",
    "        labelNum = 6\n",
    "    elif 'paper' in pathStr:\n",
    "        labelNum = 7\n",
    "    elif 'plastic' in pathStr:\n",
    "        labelNum = 8\n",
    "    elif 'shoes' in pathStr:\n",
    "        labelNum = 9\n",
    "    elif 'trash' in pathStr:\n",
    "        labelNum = 10\n",
    "    elif 'white-glass' in pathStr:\n",
    "        labelNum = 11\n",
    "    if labelNum == -1:\n",
    "        continue\n",
    "    img = Image.open(pathStr)\n",
    "    tensor = transformer(img).to(device)\n",
    "    if(tensor.shape[0] != 3):\n",
    "        rejected.append(pathStr)\n",
    "        continue\n",
    "    labelsList.append(labelNum)\n",
    "    inputImages.append(tensor)\n",
    "    \n",
    "\n",
    "\n",
    "dataset = torch.stack(inputImages).to(device)\n",
    "labels = torch.ByteTensor(labelsList)\n",
    "\n",
    "\n",
    "print(dataset.shape)\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8* len(dataset))\n",
    "validate_size = int(0.1* len(dataset))\n",
    "test_size = int(0.1* len(dataset))\n",
    "\n",
    "print(train_size)\n",
    "print(validate_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64*62*62, 128)\n",
    "        self.fc2 = nn.Linear(128, 12)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)   \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.035810856074094774\n",
      "Epoch 2, Loss: 0.03183657348155975\n",
      "Epoch 3, Loss: 0.029557222276926042\n",
      "Epoch 4, Loss: 0.02763885796070099\n",
      "Epoch 5, Loss: 0.025756762474775315\n",
      "Epoch 6, Loss: 0.0240987403690815\n",
      "Epoch 7, Loss: 0.02260261356830597\n",
      "Epoch 8, Loss: 0.02102575808763504\n",
      "Epoch 9, Loss: 0.01964906983077526\n",
      "Epoch 10, Loss: 0.018355787992477418\n",
      "Epoch 11, Loss: 0.016984615921974183\n",
      "Epoch 12, Loss: 0.015516158416867256\n",
      "Epoch 13, Loss: 0.014097649902105332\n",
      "Epoch 14, Loss: 0.012682093530893326\n",
      "Epoch 15, Loss: 0.011303008049726487\n",
      "Epoch 16, Loss: 0.009971063062548637\n",
      "Epoch 17, Loss: 0.008865347430109978\n",
      "Epoch 18, Loss: 0.008002649135887623\n",
      "Epoch 19, Loss: 0.007293289918452501\n",
      "Epoch 20, Loss: 0.007047781925648451\n",
      "Epoch 21, Loss: 0.006907192580401897\n",
      "Epoch 22, Loss: 0.0074231156706809995\n",
      "Epoch 23, Loss: 0.010239873826503754\n",
      "Epoch 24, Loss: 0.012988388612866402\n",
      "Epoch 25, Loss: 0.009158784002065658\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(25):  # Adjust the number of epochs as needed\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, train_size, 64):\n",
    "        inputs, curLabels = dataset[i:i+64].to(device), labels[i:i+64].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, curLabels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / train_size}\")\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 54.69%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(train_size, train_size+validate_size, 64):\n",
    "        inputs, curLabels = dataset[index:index+64].to(device), labels[index:index+64].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the validation set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test_size set: 39.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables for tracking accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test set and make predictions\n",
    "with torch.no_grad():\n",
    "    for index in range(train_size+validate_size, train_size+validate_size+test_size, 64):\n",
    "        inputs, curLabels = dataset[index:index+64].to(device), labels[index:index+64].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += curLabels.size(0)\n",
    "        correct += (predicted == curLabels).sum().item()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test_size set: {accuracy:.2f}%\")# Load and preprocess the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codejam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
